model,algo,config,config_detail,quant_duration,load_mem_allot,load_mem_reserved,ppl_mem_allot,ppl_mem_reserved,leaderboard_mem_allot,leaderboard_mem_reserved,ppl_wikitext,ppl_c4,duration_wikitext,duration_c4,duration_leaderboard,ifeval,bbh,mathlevel5,gpqa,musr,mmlupro
Llama-2-7b-hf,gptq,b3g128,"BaseQuantizeConfig(bits=3, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Llama-2-7b-hf-b3g128-gptq', model_file_base_name='gptq_model-3bit-128g')",817.5435881614685,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b4g128,"BaseQuantizeConfig(bits=4, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Meta-Llama-3-8B-b4g128-gptq', model_file_base_name='gptq_model-4bit-128g')",966.0167262554168,8519680,33554432,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b3g32,"BaseQuantizeConfig(bits=3, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Llama-2-7b-hf-b3g32-gptq', model_file_base_name='gptq_model-3bit-32g')",826.258552312851,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b3g64,"BaseQuantizeConfig(bits=3, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Llama-2-7b-hf-b3g64-gptq', model_file_base_name='gptq_model-3bit-64g')",818.5346009731293,8519680,33554432,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b3g128,"BaseQuantizeConfig(bits=3, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Meta-Llama-3-8B-b3g128-gptq', model_file_base_name='gptq_model-3bit-128g')",967.3104581832886,8519680,33554432,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b4g32,"BaseQuantizeConfig(bits=4, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Meta-Llama-3-8B-b4g32-gptq', model_file_base_name='gptq_model-4bit-32g')",980.0271611213684,8519680,33554432,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b3g128,"BaseQuantizeConfig(bits=3, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Llama-2-13b-hf-b3g128-gptq', model_file_base_name='gptq_model-3bit-128g')",1540.2862856388092,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b4g128,"BaseQuantizeConfig(bits=4, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Llama-2-7b-hf-b4g128-gptq', model_file_base_name='gptq_model-4bit-128g')",812.6538500785828,8519680,33554432,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b4g32,"BaseQuantizeConfig(bits=4, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Llama-2-7b-hf-b4g32-gptq', model_file_base_name='gptq_model-4bit-32g')",825.9306561946869,8519680,33554432,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b3g32,"BaseQuantizeConfig(bits=3, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Meta-Llama-3-8B-b3g32-gptq', model_file_base_name='gptq_model-3bit-32g')",976.306769132614,8519680,33554432,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b3g32,"BaseQuantizeConfig(bits=3, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Llama-2-13b-hf-b3g32-gptq', model_file_base_name='gptq_model-3bit-32g')",1546.1331825256348,8519680,52428800,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b3g64,"BaseQuantizeConfig(bits=3, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Meta-Llama-3-8B-b3g64-gptq', model_file_base_name='gptq_model-3bit-64g')",1056.0845897197723,8519680,33554432,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b4g32,"BaseQuantizeConfig(bits=4, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Llama-2-13b-hf-b4g32-gptq', model_file_base_name='gptq_model-4bit-32g')",1545.0226376056671,8519680,52428800,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b3g64,"BaseQuantizeConfig(bits=3, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Llama-2-13b-hf-b3g64-gptq', model_file_base_name='gptq_model-3bit-64g')",1538.153817653656,8519680,52428800,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b4g64,"BaseQuantizeConfig(bits=4, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Llama-2-7b-hf-b4g64-gptq', model_file_base_name='gptq_model-4bit-64g')",819.5383853912354,8519680,33554432,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b4g64,"BaseQuantizeConfig(bits=4, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Meta-Llama-3-8B-b4g64-gptq', model_file_base_name='gptq_model-4bit-64g')",974.3064377307892,8519680,33554432,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b4g128,"BaseQuantizeConfig(bits=4, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Llama-2-13b-hf-b4g128-gptq', model_file_base_name='gptq_model-4bit-128g')",1538.8324785232544,8519680,52428800,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b4g64,"BaseQuantizeConfig(bits=4, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Llama-2-13b-hf-b4g64-gptq', model_file_base_name='gptq_model-4bit-64g')",1540.7657170295715,8519680,52428800,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
