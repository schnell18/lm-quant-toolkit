model,algo,config,config_detail,quant_duration,model_storage_size,load_mem_allot,load_mem_reserved,ppl_mem_allot,ppl_mem_reserved,leaderboard_mem_allot,leaderboard_mem_reserved,ppl_wikitext,ppl_c4,duration_wikitext,duration_c4,duration_leaderboard,ifeval,bbh,mathlevel5,gpqa,musr,mmlupro
Llama-2-7b-hf,gptq,b8g64,"BaseQuantizeConfig(bits=8, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,7309052368,7308960256,7325351936,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b8g32,"BaseQuantizeConfig(bits=8, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,9740602160,9740509696,9758048256,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b8g128,"BaseQuantizeConfig(bits=8, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,9249868200,9249776128,9250537472,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b8g128,"BaseQuantizeConfig(bits=8, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,7157270928,7157178880,7161774080,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b8g64,"BaseQuantizeConfig(bits=8, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,13945962720,13945846272,13962838016,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b8g32,"BaseQuantizeConfig(bits=8, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,14540702432,14540585472,14547943424,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b8g32,"BaseQuantizeConfig(bits=8, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,7612615512,7612523008,7631536128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b8g64,"BaseQuantizeConfig(bits=8, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,9413446064,9413353984,9426698240,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b8g128,"BaseQuantizeConfig(bits=8, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,13648593120,13648476672,13658750976,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
