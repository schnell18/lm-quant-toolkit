size = 0.1,
color = "blue"
) +
geom_hline(
yintercept = min_ppl,
linetype = "dashed",
size = 0.1,
color = "blue"
) +
annotate("text", x = 15.8, y = min_ppl * 1.00, label = "FP16") +
scale_x_break(c(5.5, 15.6)) +
scale_x_continuous(
limits = c(2.8, 16.2),
breaks = seq(2.8, 5.5, 0.20),
sec.axis = sec_axis(~ 100 * (16 - .) / 16, name = "% Memery Reduction")
) +
scale_y_continuous(
limits = c(min_ppl * 0.99, min_ppl * 1.20),
breaks = seq(6.95, 6.95 * 1.20, 0.25),
sec.axis = sec_axis(~ 100 * (. - 6.95) / 6.95, name = "% Degradation")
) +
labs(x = "Bit Budget", y = "Perplexity") +
theme_gray(base_size = 14) +
guides(
shape = guide_legend(title = "Method:"),
color = guide_legend(title = "Method:")
) +
theme(
legend.position = "bottom",
legend.text = element_text(size = 14),
legend.title = element_text(size = 14)
) +
facet_wrap(~model, scales = "free") +
scale_color_solarized()
plt6
library(tidyverse)
library(ggthemes)
library(ggbreak)
library(readr)
all_cols <- c(
"model", "algo", "config",
"bpp", "ppl_wikitext", "ppl_c4"
)
df_all <- read_csv("data/combined.csv") |>
select(all_of(all_cols)) |>
filter(
algo == "mxq" | algo == "pct5" | algo == "fp16" | algo == "awq" | algo == "hqq"
) |>
mutate(
model = factor(
model,
levels = c("Llama-2-7b-hf", "Meta-Llama-3-8B", "Llama-2-13b-hf"),
labels = c("Llama-2-7B", "Llama-3-8B", "Llama-2-13B")
),
algo = factor(
algo,
levels = c("mxq", "pct5", "fp16", "awq", "gptq", "bnb", "hqq"),
labels = c("MXQ", "PCT5", "FP16", "AWQ", "GPTQ", "BnB", "HQQ"),
)
)
df_wikitxt_all <- df_all |>
rename(ppl = ppl_wikitext)
df_c4_all <- df_all |>
rename(ppl = ppl_c4)
model_name <- "Llama-2-13B"
df_wikitxt <- df_wikitxt_all |>
filter(
model == model_name & bpp >= 2.5
)
min_ppl <- min(df_wikitxt$ppl)
min_bpp <- min(df_wikitxt$bpp)
plt1 <- ggplot(
subset(df_wikitxt, algo != "MXQ"),
aes(x = bpp, y = ppl),
) +
geom_point(
data = subset(df_wikitxt, algo == "MXQ"),
size = 0.5,
aes(shape = algo, color = algo, y = ppl)
) +
geom_point(size = 1.5, aes(shape = algo, color = algo, y = ppl)) +
geom_hline(
yintercept = min_ppl * 1.02,
linetype = "dashed",
size = 0.1,
color = "blue"
) +
geom_hline(
yintercept = min_ppl * 1.01,
linetype = "dashed",
size = 0.1,
color = "blue"
) +
geom_hline(
yintercept = min_ppl,
linetype = "dashed",
size = 0.1,
color = "blue"
) +
annotate("text", x = 15.8, y = min_ppl * 1.00, label = "FP16") +
scale_x_break(c(5.5, 15.6)) +
scale_x_continuous(
limits = c(2.8, 16.2),
breaks = seq(2.8, 5.5, 0.20),
sec.axis = sec_axis(~ 100 * (16 - .) / 16, name = "% Memery Reduction")
) +
scale_y_continuous(
limits = c(min_ppl * 0.99, min_ppl * 1.20),
breaks = seq(4.63, 4.63 * 1.20, 0.20),
sec.axis = sec_axis(~ 100 * (. - 4.63) / 4.63, name = "% Degradation")
) +
labs(x = "Bit Budget", y = "Perplexity") +
theme_gray(base_size = 14) +
guides(
shape = guide_legend(title = "Method:"),
color = guide_legend(title = "Method:")
) +
theme(
legend.position = "bottom",
legend.text = element_text(size = 14),
legend.title = element_text(size = 14)
) +
facet_wrap(~model, scales = "free") +
scale_color_solarized()
plt1
library(tidyverse)
library(ggthemes)
library(ggbreak)
library(readr)
all_cols <- c(
"model", "algo", "config",
"bpp", "ppl_wikitext", "ppl_c4"
)
df_all <- read_csv("data/combined.csv") |>
select(all_of(all_cols)) |>
filter(
algo == "mxq" | algo == "pct5" | algo == "pct6" | algo == "fp16" | algo == "awq" | algo == "hqq"
) |>
mutate(
model = factor(
model,
levels = c("Llama-2-7b-hf", "Meta-Llama-3-8B", "Llama-2-13b-hf"),
labels = c("Llama-2-7B", "Llama-3-8B", "Llama-2-13B")
),
algo = factor(
algo,
levels = c("mxq", "pct5", "pct6", "fp16", "awq", "gptq", "bnb", "hqq"),
labels = c("MXQ", "PCT5", "PCT6", "FP16", "AWQ", "GPTQ", "BnB", "HQQ"),
)
)
df_wikitxt_all <- df_all |>
rename(ppl = ppl_wikitext)
df_c4_all <- df_all |>
rename(ppl = ppl_c4)
model_name <- "Llama-2-13B"
df_wikitxt <- df_wikitxt_all |>
filter(
model == model_name & bpp >= 2.5
)
min_ppl <- min(df_wikitxt$ppl)
min_bpp <- min(df_wikitxt$bpp)
plt1 <- ggplot(
subset(df_wikitxt, algo != "MXQ"),
aes(x = bpp, y = ppl),
) +
geom_point(
data = subset(df_wikitxt, algo == "MXQ"),
size = 0.5,
aes(shape = algo, color = algo, y = ppl)
) +
geom_point(size = 1.5, aes(shape = algo, color = algo, y = ppl)) +
geom_hline(
yintercept = min_ppl * 1.02,
linetype = "dashed",
size = 0.1,
color = "blue"
) +
geom_hline(
yintercept = min_ppl * 1.01,
linetype = "dashed",
size = 0.1,
color = "blue"
) +
geom_hline(
yintercept = min_ppl,
linetype = "dashed",
size = 0.1,
color = "blue"
) +
annotate("text", x = 15.8, y = min_ppl * 1.00, label = "FP16") +
scale_x_break(c(5.5, 15.6)) +
scale_x_continuous(
limits = c(2.8, 16.2),
breaks = seq(2.8, 5.5, 0.20),
sec.axis = sec_axis(~ 100 * (16 - .) / 16, name = "% Memery Reduction")
) +
scale_y_continuous(
limits = c(min_ppl * 0.99, min_ppl * 1.20),
breaks = seq(4.63, 4.63 * 1.20, 0.20),
sec.axis = sec_axis(~ 100 * (. - 4.63) / 4.63, name = "% Degradation")
) +
labs(x = "Bit Budget", y = "Perplexity") +
theme_gray(base_size = 14) +
guides(
shape = guide_legend(title = "Method:"),
color = guide_legend(title = "Method:")
) +
theme(
legend.position = "bottom",
legend.text = element_text(size = 14),
legend.title = element_text(size = 14)
) +
facet_wrap(~model, scales = "free") +
scale_color_solarized()
plt1
library(tidyverse)
library(ggthemes)
library(readr)
all_cols1 <- c(
"model",
"algo",
"config",
"bpp",
"load_mem_allot"
)
all_cols2 <- c(
"model",
"algo",
"config.x",
"bpp",
"load_mem_allot"
)
df_all <- read_csv("data/combined.csv")
df_wo_mxq <- df_all |>
filter(algo != "mxq") |>
select(all_of(all_cols1))
df_fp16 <- df_all |>
filter(algo == "fp16")
df_baseline <- df_all |>
filter(algo == "hqq") |>
left_join(df_fp16, by = c("model"), suffix = c(".x", "")) |>
select(all_of(all_cols2)) |>
rename(
config = config.x,
)
df_hqq <- df_wo_mxq |> filter(algo == "hqq" & !str_detect(config, "^mxq"))
df_mxq <- df_all |> filter(algo == "mxq" | algo == "pct5" | algo == "pct6")
df_mxq1 <- df_hqq |>
left_join(
df_mxq,
suffix = c(".x", ""),
join_by(model, bpp)
) |>
select(c("model", "algo", "config.x", "bpp", "load_mem_allot")) |>
rename(
config = config.x
)
disp <- bind_rows(df_wo_mxq, df_baseline, df_mxq1) |>
filter(str_detect(config, "^b4")) |>
mutate(
model = factor(
model,
levels = c("Llama-2-7b-hf", "Meta-Llama-3-8B", "Llama-2-13b-hf"),
labels = c("Llama-2-7B", "Llama-3-8B", "Llama-2-13B")
),
algo = factor(algo, levels = (c("awq", "gptq", "hqq", "mxq", "pct5", "pct6", "bnb", "fp16"))),
config = factor(config, levels = (c("b4g32", "b4g64", "b4g128")))
) |>
filter(algo != "bnb")
plt1 <- ggplot(disp, aes(x = algo, y = load_mem_allot, fill = algo)) +
geom_col(aes(x = load_mem_allot, y = algo), show.legend = FALSE) +
geom_text(
aes(0, y = algo, label = toupper(algo)),
hjust = 0,
nudge_x = 0.3,
colour = "white",
size = 3
) +
labs(y = "Algorithm", x = "GPU Memory(GiB)") +
scale_x_continuous(
limits = c(0, 22),
breaks = seq(0, 22, by = 4),
expand = c(0, 0),
position = "bottom"
) +
scale_y_discrete(expand = expansion(add = c(0, 0.5))) +
theme(
panel.background = element_rect(fill = "white"),
panel.grid.major.x = element_line(color = "#A8BAC4", size = 0.3),
axis.ticks.length = unit(0, "mm"),
axis.title = element_blank(),
axis.text.y = element_blank()
) +
facet_grid(config ~ model) +
scale_color_solarized()
plt1
source("~/study/aut-study/master-thesis/data-vis/plot-mxq-gap.R")
source("~/study/aut-study/master-thesis/data-vis/plot-mem-consumption.R")
source("~/study/aut-study/master-thesis/data-vis/plot-quant-cfg-diff.R")
final_plot1
source("~/study/aut-study/master-thesis/data-vis/plot-quant-cfg-diff.R")
source("~/study/aut-study/master-thesis/data-vis/plot-quant-cfg-diff.R")
library(tidyverse)
library(openxlsx)
library(knitr)
library(kableExtra)
dump_latex_table <- function(df, latex_file = "table.tex") {
options(knitr.kable.NA = "-")
tabular <- df |>
kable(
format = "latex",
booktabs = TRUE,
linesep = "",
align = c("cccccccccccc"),
caption = "My formatted LLM quantization table.",
label = "tab:experiment-result",
col.names = c(
"Method", "Config", "BPP",
"WikiText2", "C4", "MEM",
"WikiText2", "C4", "MEM",
"WikiText2", "C4", "MEM"
)
) |>
kable_styling(latex_options = c("hold_position")) |>
add_header_above(
c(" " = 3, "Llama-2-7B" = 3, "Llama-2-13B" = 3, "Llama-3-8B" = 3)
) |>
collapse_rows(columns = 2, latex_hline = "major")
tabular <- gsub(
"\\begin{tabular}",
"\\begin{adjustbox}{width=\\textwidth,keepaspectratio}\n\\begin{tabular}",
tabular,
fixed = TRUE
)
tabular <- gsub(
"\\end{tabular}",
"\\end{tabular}\n\\end{adjustbox}",
tabular,
fixed = TRUE
)
head <- r"(
\documentclass{article}
\usepackage{booktabs,makecell,multirow,threeparttable}
\usepackage{adjustbox}
\begin{document}
)"
tail <- r"(
\end{document}
)"
out <- paste(
head,
tabular,
tail,
sep = "\n"
)
fh <- file(latex_file)
writeLines(out, fh)
close(fh)
}
args <- commandArgs(trailingOnly = TRUE)
if (length(args) == 0) {
csv_fp <- "data/combined.csv"
} else {
csv_fp <- args[1]
}
all_cols <- c(
"model", "algo", "config",
"bpp", "ppl_wikitext", "ppl_c4",
"memory"
)
csv_fp <- "/fdata/llm/mxq/results/tail-boost/data/combined.csv"
df_all <- read_csv(csv_fp) |>
filter(
is.na(attempt)
) |>
mutate(
ppl_wikitext = round(ppl_wikitext, digits = 2),
ppl_c4 = round(ppl_c4, digits = 2),
memory = round(load_mem_allot, digits = 2)
) |>
mutate(
model = factor(
model,
levels = c("Llama-2-7b-hf", "Llama-2-13b-hf", "Meta-Llama-3-8B"),
labels = c("Llama-2-7B", "Llama-2-13B", "Llama-3-8B")
),
algo = factor(
algo,
levels = c("mxq", "fp16", "awq", "gptq", "bnb", "hqq"),
labels = c("MXQ", "FP16", "AWQ", "GPTQ", "BnB", "HQQ"),
),
config = factor(
config,
levels = c(
"base",
"b4g32", "b4g64", "b4g128",
"b3g32", "b3g64", "b3g128"
# "4_51", "4_25", "4_13",
# "3_51", "3_25", "3_13",
# "3_65", "6_89", "5_72",
# "3_07", "4_01", "5_02",
)
)
) |>
select(all_of(all_cols))
latex_cols <- c(
"algo", "config", "bpp",
"ppl_wikitext_Llama-2-7B", "ppl_c4_Llama-2-7B", "memory_Llama-2-7B",
"ppl_wikitext_Llama-2-13B", "ppl_c4_Llama-2-13B", "memory_Llama-2-13B",
"ppl_wikitext_Llama-3-8B", "ppl_c4_Llama-3-8B", "memory_Llama-3-8B"
)
df_latex <- df_all |>
filter(bpp >= 3.03 & bpp < 8.0 | bpp >= 16.00) |>
# filter(
#   algo != "MXQ" |
#     bpp == 4.51 |
#     bpp == 4.25 |
#     bpp == 4.13 |
#     bpp == 3.51 |
#     bpp == 3.25 |
#     bpp == 3.13 |
#     bpp == 3.65 |
#     bpp == 5.72 |
#     bpp == 6.89 |
#     bpp == 3.07 |
#     bpp == 4.01 |
#     bpp == 5.02
# ) |>
pivot_wider(
names_from = model,
values_from = c(ppl_wikitext, ppl_c4, memory),
names_vary = "slowest"
) |>
select(all_of(latex_cols)) |>
arrange(config)
View(df_latex)
View(df_all)
csv_fp <- "/fdata/llm/mxq/results/tail-boost/data/combined.csv"
df_all <- read_csv(csv_fp) |>
# filter(
#   is.na(attempt)
# ) |>
mutate(
ppl_wikitext = round(ppl_wikitext, digits = 2),
ppl_c4 = round(ppl_c4, digits = 2),
memory = round(load_mem_allot, digits = 2)
) |>
mutate(
model = factor(
model,
levels = c("Llama-2-7b-hf", "Llama-2-13b-hf", "Meta-Llama-3-8B"),
labels = c("Llama-2-7B", "Llama-2-13B", "Llama-3-8B")
),
algo = factor(
algo,
levels = c("mxq", "fp16", "awq", "gptq", "bnb", "hqq"),
labels = c("MXQ", "FP16", "AWQ", "GPTQ", "BnB", "HQQ"),
),
config = factor(
config,
levels = c(
"base",
"b4g32", "b4g64", "b4g128",
"b3g32", "b3g64", "b3g128"
# "4_51", "4_25", "4_13",
# "3_51", "3_25", "3_13",
# "3_65", "6_89", "5_72",
# "3_07", "4_01", "5_02",
)
)
) |>
select(all_of(all_cols))
View(df_all)
source("~/work/lm-quant-toolkit/data-vis/gen-table-mxq-llm.R")
View(df_all)
library(tidyverse)
args <- commandArgs(trailingOnly = TRUE)
if (length(args) == 0) {
csv_fp <- "data/llama-sensitivity1.csv"
} else {
csv_fp <- args[1]
}
df_all <- read_csv(csv_fp)
View(df_all)
df_layer <- df_all |>
group_by(model, layerA) |>
summarise(
sensitivity = sum(sensitivity)
) |>
arrange(sensitivity)
df_layer <- df_all |>
group_by(model, layer) |>
summarise(
sensitivity = sum(sensitivity)
) |>
arrange(sensitivity)
View(df_layer)
df_layer <- df_all |>
group_by(model, layer) |>
summarise(
sensitivity = sum(sensitivity)
) |>
arrange(model, sensitivity)
View(df_layer)
?arrange
df_layer <- df_all |>
group_by(model, layer) |>
summarise(
sensitivity = sum(sensitivity)
) |>
arrange(model, desc(sensitivity))
View(df_layer)
