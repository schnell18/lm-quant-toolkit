model,algo,config,config_detail,quant_duration,model_storage_size,load_mem_allot,load_mem_reserved,ppl_mem_allot,ppl_mem_reserved,leaderboard_mem_allot,leaderboard_mem_reserved,ppl_wikitext,ppl_c4,duration_wikitext,duration_c4,duration_leaderboard,ifeval,bbh,mathlevel5,gpqa,musr,mmlupro
Llama-2-7b-hf,gptq,b8g64,"BaseQuantizeConfig(bits=8, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Llama-2-7b-hf-b8g64-gptq', model_file_base_name='gptq_model-8bit-64g')",816.7253777980804,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b8g32,"BaseQuantizeConfig(bits=8, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0.0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b8g128,"BaseQuantizeConfig(bits=8, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Meta-Llama-3-8B-b8g128-gptq', model_file_base_name='gptq_model-8bit-128g')",973.6111924648284,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b8g128,"BaseQuantizeConfig(bits=8, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Llama-2-7b-hf-b8g128-gptq', model_file_base_name='gptq_model-8bit-128g')",818.6892747879028,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b8g64,"BaseQuantizeConfig(bits=8, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Llama-2-13b-hf-b8g64-gptq', model_file_base_name='gptq_model-8bit-64g')",1568.4314601421356,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b8g32,"BaseQuantizeConfig(bits=8, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Llama-2-13b-hf-b8g32-gptq', model_file_base_name='gptq_model-8bit-32g')",1557.962459564209,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b8g32,"BaseQuantizeConfig(bits=8, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Llama-2-7b-hf-b8g32-gptq', model_file_base_name='gptq_model-8bit-32g')",825.0034923553467,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b8g64,"BaseQuantizeConfig(bits=8, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0.0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b8g128,"BaseQuantizeConfig(bits=8, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path='/fdata/llm/mxq/snapshots/meta-llama/Llama-2-13b-hf-b8g128-gptq', model_file_base_name='gptq_model-8bit-128g')",1545.3703949451449,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
