model,algo,config,config_detail,quant_duration,load_mem_allot,load_mem_reserved,ppl_mem_allot,ppl_mem_reserved,leaderboard_mem_allot,leaderboard_mem_reserved,ppl_wikitext,ppl_c4,duration_wikitext,duration_c4,duration_leaderboard,ifeval,bbh,mathlevel5,gpqa,musr,mmlupro
Llama-2-7b-hf,gptq,b3g128,"BaseQuantizeConfig(bits=3, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,11677207552,12276727808,11677207552,12276727808,0,0,6.3173,8.2991,0.419,0.419,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b4g128,"BaseQuantizeConfig(bits=4, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,11868616192,11903434752,11868616192,11926503424,0,0,97.0309,27.7734,0.097,0.097,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b3g32,"BaseQuantizeConfig(bits=3, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,6531560448,7163871232,6531560448,7344226304,0,0,5.9409,7.8088,0.424,0.425,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b3g64,"BaseQuantizeConfig(bits=3, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,6704018432,7128219648,6704018432,7308574720,0,0,6.1327,8.0688,0.421,0.42,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b3g128,"BaseQuantizeConfig(bits=3, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,9840325632,9923723264,9840325632,10456399872,0,0,52.779,30.0427,0.457,0.458,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b4g32,"BaseQuantizeConfig(bits=4, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,14034061824,14080278528,14034061824,14080278528,0,0,8.805,10.4355,0.098,0.098,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b3g128,"BaseQuantizeConfig(bits=3, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,12277770752,12582912000,12277770752,12582912000,0,0,5.2384,7.1918,0.823,0.825,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b4g128,"BaseQuantizeConfig(bits=4, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,8028009984,8589934592,8028009984,8589934592,0,0,5.3939,7.1774,0.084,0.084,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b4g32,"BaseQuantizeConfig(bits=4, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,9919186944,10158604288,9919186944,10158604288,0,0,5.3859,7.1101,0.085,0.085,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b3g32,"BaseQuantizeConfig(bits=3, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,10287055872,10311696384,10287055872,10311696384,0,0,17.758,17.9848,0.461,0.462,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b3g32,"BaseQuantizeConfig(bits=3, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,12269630464,12410945536,12269630464,12696158208,0,0,5.0878,6.9585,0.833,0.831,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b3g64,"BaseQuantizeConfig(bits=3, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,10405249536,10452205568,10405249536,10452205568,0,0,11.1596,14.3308,0.459,0.459,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b4g32,"BaseQuantizeConfig(bits=4, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,17555534848,17764974592,17555534848,17764974592,0,0,4.7167,6.537,0.159,0.159,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b3g64,"BaseQuantizeConfig(bits=3, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,12480541696,12715032576,12480541696,13000245248,0,0,5.1423,7.0625,0.826,0.825,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b4g64,"BaseQuantizeConfig(bits=4, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,10039182848,10284433408,10039182848,10284433408,0,0,5.3901,7.1289,0.084,0.085,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b4g64,"BaseQuantizeConfig(bits=4, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,14185842176,14248050688,14185842176,14248050688,0,0,11.8327,11.7743,0.098,0.098,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b4g128,"BaseQuantizeConfig(bits=4, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,14377522176,14841544704,14377522176,14841544704,0,0,4.7422,6.5699,0.159,0.158,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b4g64,"BaseQuantizeConfig(bits=4, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,17763132416,18134073344,17763132416,18134073344,0,0,4.7325,6.5575,0.159,0.159,0,0,0,0,0,0,0
