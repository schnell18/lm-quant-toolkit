model,algo,config,config_detail,quant_duration,model_storage_size,load_mem_allot,load_mem_reserved,ppl_mem_allot,ppl_mem_reserved,leaderboard_mem_allot,leaderboard_mem_reserved,ppl_wikitext,ppl_c4,duration_wikitext,duration_c4,duration_leaderboard,ifeval,bbh,mathlevel5,gpqa,musr,mmlupro
Llama-2-7b-hf,gptq,b8g64,"BaseQuantizeConfig(bits=8, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,0,0,0,16567370752,16575889408,0,0,5.186,6.9462,0.245,0.245,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b8g32,"BaseQuantizeConfig(bits=8, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,0,0,0,10946580480,11318329344,0,0,5.8131,8.9833,0.278,0.278,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b8g128,"BaseQuantizeConfig(bits=8, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,0,0,0,18998920192,19008585728,0,0,5.8155,8.9844,0.276,0.276,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b8g128,"BaseQuantizeConfig(bits=8, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,0,0,0,14778336256,14814281728,0,0,5.1863,6.9459,0.244,0.244,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b8g64,"BaseQuantizeConfig(bits=8, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,0,0,0,21111659520,21124612096,0,0,4.6308,6.4455,0.5,0.5,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b8g32,"BaseQuantizeConfig(bits=8, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,0,0,0,15893532160,15997075456,0,0,4.6307,6.4461,0.503,0.504,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b8g32,"BaseQuantizeConfig(bits=8, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,0,0,0,14930117632,14956888064,0,0,5.1861,6.9465,0.246,0.246,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b8g64,"BaseQuantizeConfig(bits=8, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,0,0,0,10619424768,10986979328,0,0,5.814,8.9836,0.278,0.278,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b8g128,"BaseQuantizeConfig(bits=8, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,0,0,0,14998105600,15107883008,0,0,4.631,6.446,0.5,0.5,0,0,0,0,0,0,0
