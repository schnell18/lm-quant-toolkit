model,algo,config,config_detail,quant_duration,model_storage_size,load_mem_allot,load_mem_reserved,ppl_mem_allot,ppl_mem_reserved,leaderboard_mem_allot,leaderboard_mem_reserved,ppl_wikitext,ppl_c4,duration_wikitext,duration_c4,duration_leaderboard,ifeval,bbh,mathlevel5,gpqa,musr,mmlupro
Llama-2-7b-hf,awq,b4g128,"{'w_bit': 4, 'q_group_size': 128, 'zero_point': True, 'version': 'GEMM'}",0,3889391512,3889324544,3902799872,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-7b-hf,awq,b4g32,"{'w_bit': 4, 'q_group_size': 32, 'zero_point': True, 'version': 'GEMM'}",0,4268845408,4268777984,4284481536,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-7b-hf,awq,b4g64,"{'w_bit': 4, 'q_group_size': 64, 'zero_point': True, 'version': 'GEMM'}",0,4015876056,4015809024,4020240384,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,awq,b4g128,"{'w_bit': 4, 'q_group_size': 128, 'zero_point': True, 'version': 'GEMM'}",0,5727938576,5727871488,5737807872,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,awq,b4g32,"{'w_bit': 4, 'q_group_size': 32, 'zero_point': True, 'version': 'GEMM'}",0,6136883592,6136816128,6150946816,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,awq,b4g64,"{'w_bit': 4, 'q_group_size': 64, 'zero_point': True, 'version': 'GEMM'}",0,5864253456,5864186368,5865734144,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-7b-hf,fp16,base,{},0,13476876272,13476848128,13486784512,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-13b-hf,fp16,base,{},0,26031784912,20628787712,20638072832,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,fp16,base,{},0,16060556376,16060539392,16066281472,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b3g128,"BaseQuantizeConfig(bits=3, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,3078145712,3078054400,3082813440,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b3g32,"BaseQuantizeConfig(bits=3, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,3438626944,3438535168,3445620736,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b3g64,"BaseQuantizeConfig(bits=3, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,3198306040,3198214656,3214934016,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b4g128,"BaseQuantizeConfig(bits=4, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,3893970768,4710032384,4729077760,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b4g32,"BaseQuantizeConfig(bits=4, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,4273424664,5089485824,5110759424,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-7b-hf,gptq,b4g64,"BaseQuantizeConfig(bits=4, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,4020455312,4836516864,4846518272,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b3g128,"BaseQuantizeConfig(bits=3, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,5656783352,5656668672,5668601856,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b3g32,"BaseQuantizeConfig(bits=3, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,6363036632,6362921472,6364856320,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b3g64,"BaseQuantizeConfig(bits=3, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,5892200944,5892086272,5897191424,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b4g128,"BaseQuantizeConfig(bits=4, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,7255145048,8309685248,8331984896,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b4g32,"BaseQuantizeConfig(bits=4, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,7998569528,9053109248,9057599488,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Llama-2-13b-hf,gptq,b4g64,"BaseQuantizeConfig(bits=4, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,7502953048,8557493248,8571060224,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b3g128,"BaseQuantizeConfig(bits=3, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,4853712608,4853621248,4854906880,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b3g32,"BaseQuantizeConfig(bits=3, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,5242210416,5242118656,5247074304,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b3g64,"BaseQuantizeConfig(bits=3, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,4983211744,4983120384,4997513216,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b4g128,"BaseQuantizeConfig(bits=4, group_size=128, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,5732943792,6794798080,6817841152,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b4g32,"BaseQuantizeConfig(bits=4, group_size=32, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,6141888832,7203742720,7210008576,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
Meta-Llama-3-8B,gptq,b4g64,"BaseQuantizeConfig(bits=4, group_size=64, damp_percent=0.01, desc_act=False, static_groups=False, sym=True, true_sequential=True, quant_method='gptq', checkpoint_format='gptq', model_name_or_path=None, model_file_base_name=None)",0,5869258672,6931112960,6945767424,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0
